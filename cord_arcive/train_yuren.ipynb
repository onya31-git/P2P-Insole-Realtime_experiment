{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "332291e0-89e2-4522-827b-404b2614173a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f48cde7-172e-4c77-a995-bed443cef989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_positional_encoding(x):\n",
    "    \"\"\"\n",
    "    Add positional encoding to the input tensor.\n",
    "\n",
    "    Args:\n",
    "        x (Tensor): Input tensor of shape (batch_size, seq_len, d_model)\n",
    "\n",
    "    Returns:\n",
    "        Tensor: The input tensor with added positional encoding, same shape as x\n",
    "    \"\"\"\n",
    "    batch_size, seq_len, d_model = x.shape\n",
    "\n",
    "    # Initialize the positional encoding matrix of shape (seq_len, d_model)\n",
    "    pe = torch.zeros(seq_len, d_model, device=x.device)\n",
    "\n",
    "    # Create a tensor of positions (0, 1, ..., seq_len-1), shape (seq_len, 1)\n",
    "    position = torch.arange(seq_len, device=x.device).unsqueeze(1)\n",
    "\n",
    "    # Compute the denominator term for the sinusoidal functions, shape (d_model/2,)\n",
    "    div_term = torch.exp(torch.arange(0, d_model, 2, device=x.device) * (-math.log(10000.0) / d_model))\n",
    "\n",
    "    # Apply sine to even indices in the embedding dimension\n",
    "    pe[:, 0::2] = torch.sin(position * div_term)\n",
    "\n",
    "    # Apply cosine to odd indices in the embedding dimension\n",
    "    # If d_model is odd, slicing ensures no index out of range\n",
    "    pe[:, 1::2] = torch.cos(position * div_term[:(d_model // 2)])\n",
    "\n",
    "    # Reshape to (1, seq_len, d_model) so it can be broadcasted across the batch dimension\n",
    "    pe = pe.unsqueeze(0)\n",
    "\n",
    "    # Add positional encoding to the input tensor\n",
    "    return x + pe\n",
    "def compute_exponential_weights(k, m):\n",
    "    indices = torch.arange(k)  # Generate i = 0, 1, ..., k-1\n",
    "    weights = torch.exp(-m * indices)  # Compute w_i = exp(-m * i)\n",
    "    return weights / weights.sum()  # Normalize weights to sum to 1\n",
    "class EnhancedSkeletonTransformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, nhead, num_encoder_layers, num_joints, num_dims=3, dropout=0.1, seq_length=3, window_size=5):\n",
    "        super().__init__()\n",
    "\n",
    "        # Save key hyperparameters as class attributes\n",
    "        self.num_joints = num_joints\n",
    "        self.num_dims = num_dims\n",
    "        self.seq_length = seq_length\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # Feature extractor for the encoder input\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(input_dim, d_model)  # Project input features to d_model dimension\n",
    "        )\n",
    "\n",
    "        # Transformer encoder layer configuration\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model * 4,  # Feedforward layer size\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True  # Apply normalization before attention and feedforward\n",
    "        )\n",
    "\n",
    "        # Stack multiple encoder layers\n",
    "        self.transformer_encoder = nn.TransformerEncoder(\n",
    "            encoder_layer,\n",
    "            num_layers=num_encoder_layers\n",
    "        )\n",
    "\n",
    "        # Decoder input feature extractor\n",
    "        self.decoder_feature_extractor = nn.Sequential(\n",
    "            nn.Linear(num_joints * num_dims, d_model)  # Project joint input to d_model dimension\n",
    "        )\n",
    "\n",
    "        # Transformer decoder layer configuration\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "\n",
    "        # Stack multiple decoder layers\n",
    "        self.transformer_decoder = nn.TransformerDecoder(\n",
    "            decoder_layer,\n",
    "            num_layers=num_encoder_layers\n",
    "        )\n",
    "\n",
    "        # Linear layer to expand decoder output over prediction window\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(d_model * seq_length, d_model * window_size)  # From seq_length tokens to window_size predictions\n",
    "        )\n",
    "\n",
    "        # Output decoder for generating final joint coordinates\n",
    "        self.output_decoder = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model * 2),\n",
    "            nn.LayerNorm(d_model * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model * 2, d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model, num_joints * num_dims)  # Final output shape: (batch, window_size, num_joints * num_dims)\n",
    "        )\n",
    "\n",
    "        # Learnable output scaling factor\n",
    "        self.output_scale = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def forward(self, x, decoder_input):\n",
    "        \"\"\"\n",
    "        Forward pass of the EnhancedSkeletonTransformer.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of shape (batch_size, input_dim)\n",
    "            decoder_input (Tensor): Decoder input tensor of shape (batch_size, seq_length, num_joints * num_dims)\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Predicted joint sequence of shape (batch_size, window_size, num_joints * num_dims)\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "\n",
    "        # Encode the input features\n",
    "        features = self.feature_extractor(x)              # (batch_size, d_model)\n",
    "        features = features.unsqueeze(1)                  # Add sequence dimension: (batch_size, 1, d_model)\n",
    "\n",
    "        # Process decoder input\n",
    "        decoder_input = self.decoder_feature_extractor(decoder_input)  # (batch_size, seq_length, d_model)\n",
    "        # Optional: Add positional encoding to decoder_input\n",
    "        decoder_input = add_positional_encoding(decoder_input)\n",
    "\n",
    "        # Pass through transformer encoder and decoder\n",
    "        transformer_output = self.transformer_encoder(features)        # (batch_size, 1, d_model)\n",
    "        transformer_output = self.transformer_decoder(decoder_input, transformer_output)  # (batch_size, seq_length, d_model)\n",
    "\n",
    "        # Reshape for prediction\n",
    "        predict = transformer_output.reshape(batch_size, -1)           # Flatten to (batch_size, seq_length * d_model)\n",
    "        predict_next = self.predict(predict)                           # (batch_size, window_size * d_model)\n",
    "        predict_next = predict_next.reshape(batch_size, self.window_size, -1)  # (batch_size, window_size, d_model)\n",
    "\n",
    "        # Generate output joint coordinates and apply scaling\n",
    "        output = self.output_decoder(predict_next)                     # (batch_size, window_size, num_joints * num_dims)\n",
    "        output = output * self.output_scale                            # Apply learnable scaling\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241bcbf2-1b02-4bf2-a569-526eed7aae86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbbb68c-b25b-4a49-a6b9-c1ee74e445ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a82f6-d862-4da8-847c-8ddf6f594cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9af99f-680a-4ccd-b321-392d37dd35d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4daf562-d2d9-4dad-8fd2-32b2e4bec770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e57e615-16b4-4a7d-9e9f-de395f08597c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pairs = [\n",
    "    # Standing still\n",
    "    ('./data/20241115test3/Opti-track/Take 2024-11-15 03.20.00 PM.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_152500_left.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_152500_right.csv'),\n",
    "    # Bowing\n",
    "    ('./data/20241115test3/Opti-track/Take 2024-11-15 03.26.00 PM.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_153100_left.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_153100_right.csv'),\n",
    "    # Lateral body tilt\n",
    "    ('./data/20241115test3/Opti-track/Take 2024-11-15 03.32.00 PM.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_153700_left.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_153700_right.csv'),\n",
    "    # Sit and stand\n",
    "    ('./data/20241115test3/Opti-track/Take 2024-11-15 03.38.00 PM.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_154300_left.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_154300_right.csv'),\n",
    "    # Squats\n",
    "    ('./data/20241115test3/Opti-track/Take 2024-11-15 03.44.00 PM.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_154900_left.csv',\n",
    "     './data/20241115test3/insoleSensor/20241115_154900_right.csv'),\n",
    "    \n",
    "    # Test subjects\n",
    "    ('./data/20241212test4/Opti-track/Take 2024-12-12 03.06.59 PM.csv',\n",
    "     './data/20241212test4/insoleSensor/20241212_152700_left.csv',\n",
    "     './data/20241212test4/insoleSensor/20241212_152700_right.csv'),\n",
    "    ('./data/20241212test4/Opti-track/Take 2024-12-12 03.45.00 PM.csv',\n",
    "     './data/20241212test4/insoleSensor/20241212_160501_left.csv',\n",
    "     './data/20241212test4/insoleSensor/20241212_160501_right.csv'),\n",
    "    ('./data/20241212test4/Opti-track/Take 2024-12-12 04.28.00 PM.csv',\n",
    "     './data/20241212test4/insoleSensor/20241212_164800_left.csv',\n",
    "     './data/20241212test4/insoleSensor/20241212_164800_right.csv'),\n",
    "    ('./data/20241212test4/Opti-track/Take 2024-12-12 05.17.59 PM.csv',\n",
    "     './data/20241212test4/insoleSensor/20241212_173800_left.csv',\n",
    "     './data/20241212test4/insoleSensor/20241212_173800_right.csv'),\n",
    "]\n",
    "data_path=\"./data_new\"\n",
    "opti_data_path=os.path.join(data_path,\"Opti-track\")\n",
    "insole_data_path=os.path.join(data_path,\"InsoleSensor\")\n",
    "insole_data_name=os.listdir(opti_data_path)\n",
    "dataset=[]\n",
    "for name in insole_data_name:\n",
    "    if name==\".ipynb_checkpoints\":\n",
    "        continue\n",
    "    if name==\"T005S008_skeleton.csv\":\n",
    "        continue\n",
    "    user_id=name.split(\"_\")[0]\n",
    "    skeleton=name\n",
    "    left=user_id+\"_Insole_l.csv\"\n",
    "    right=user_id+\"_Insole_r.csv\"\n",
    "    skeleton_path=os.path.join(opti_data_path,skeleton)\n",
    "    left_path=os.path.join(insole_data_path,left)\n",
    "    right_path=os.path.join(insole_data_path,right)\n",
    "    dataset.append((skeleton_path,left_path,right_path))\n",
    "\n",
    "def compute_data_statistics_combined(data_pairs):\n",
    "    all_pressures = []\n",
    "    all_rotations = []\n",
    "    all_accels = []\n",
    "\n",
    "    for opti_path, left_path, right_path in data_pairs:\n",
    "        # 读取左右脚数据，跳过首行（标题）\n",
    "        left_data = pd.read_csv(left_path, skiprows=1, header=None)\n",
    "        right_data = pd.read_csv(right_path, skiprows=1, header=None)\n",
    "\n",
    "        # 对齐长度\n",
    "        min_length = min(len(left_data), len(right_data))\n",
    "        left_data = left_data.iloc[:min_length, :]\n",
    "        right_data = right_data.iloc[:min_length, :]\n",
    "\n",
    "        # 提取压力、旋转、加速度数据\n",
    "        pressure_data = pd.concat([left_data.iloc[:, :35], right_data.iloc[:, :35]], axis=1)\n",
    "        rotation_data = pd.concat([left_data.iloc[:, 35:38], right_data.iloc[:, 35:38]], axis=1)\n",
    "        accel_data = pd.concat([left_data.iloc[:, 38:41], right_data.iloc[:, 38:41]], axis=1)\n",
    "\n",
    "        pressure_combined = pressure_data.fillna(0.0)\n",
    "        rotation_combined = rotation_data.fillna(0.0)\n",
    "        accel_combined = accel_data.fillna(0.0)\n",
    "\n",
    "        # 添加到列表\n",
    "        all_pressures.append(pressure_combined)\n",
    "        all_rotations.append(rotation_combined)\n",
    "        all_accels.append(accel_combined)\n",
    "\n",
    "    # 拼接所有样本（行方向拼接）\n",
    "    pressure_all = pd.concat(all_pressures, axis=0).values  # numpy数组\n",
    "    rotation_all = pd.concat(all_rotations, axis=0).values\n",
    "    accel_all = pd.concat(all_accels, axis=0).values\n",
    "\n",
    "    print(\"pressure_all shape:\", pressure_all.shape)\n",
    "    print(\"rotation_all shape:\", rotation_all.shape)\n",
    "    print(\"accel_all shape:\", accel_all.shape)\n",
    "    summary = {\n",
    "        'pressure': {\n",
    "            'min': np.min(pressure_all, axis=0),\n",
    "            'max': np.max(pressure_all, axis=0),\n",
    "            'mean': np.mean(pressure_all, axis=0),\n",
    "            'std': np.std(pressure_all, axis=0)\n",
    "        },\n",
    "        'rotation': {\n",
    "            'min': np.min(rotation_all, axis=0),\n",
    "            'max': np.max(rotation_all, axis=0),\n",
    "            'mean': np.mean(rotation_all, axis=0),\n",
    "            'std': np.std(rotation_all, axis=0)\n",
    "        },\n",
    "        'accel': {\n",
    "            'min': np.min(accel_all, axis=0),\n",
    "            'max': np.max(accel_all, axis=0),\n",
    "            'mean': np.mean(accel_all, axis=0),\n",
    "            'std': np.std(accel_all, axis=0)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b70e47dc-f8d6-464b-93cf-6ea616f787bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_combine_data(file_pairs):\n",
    "    all_skeleton_data = []\n",
    "    all_pressure_left = []\n",
    "    all_pressure_right = []\n",
    "\n",
    "    for skeleton_file, left_file, right_file in file_pairs:\n",
    "        # Load CSV files\n",
    "        skeleton = pd.read_csv(skeleton_file)\n",
    "        left = pd.read_csv(left_file, dtype=float, low_memory=False)\n",
    "        right = pd.read_csv(right_file, dtype=float, low_memory=False)\n",
    "\n",
    "        # Truncate to the shortest sequence length across the three\n",
    "        min_length = min(len(skeleton), len(left), len(right))\n",
    "        num_joints_points = skeleton.shape[1]\n",
    "\n",
    "        # Append processed data\n",
    "        all_skeleton_data.append(skeleton.iloc[:min_length])\n",
    "        all_pressure_left.append(left.iloc[:min_length])\n",
    "        all_pressure_right.append(right.iloc[:min_length])\n",
    "\n",
    "    return (\n",
    "        pd.concat(all_skeleton_data, ignore_index=True),\n",
    "        pd.concat(all_pressure_left, ignore_index=True),\n",
    "        pd.concat(all_pressure_right, ignore_index=True),\n",
    "    )\n",
    "def preprocess_pressure_data_temp(left_data, right_data):\n",
    "    \"\"\"\n",
    "    Preprocess pressure, rotation, and acceleration data from both feet.\n",
    "\n",
    "    Steps:\n",
    "        1. Extract pressure/rotation/acceleration components from raw CSVs.\n",
    "        2. Apply rolling average smoothing.\n",
    "        3. Interpolate missing (NaN) values.\n",
    "        4. Normalize and standardize the data.\n",
    "        5. Concatenate all features into a single matrix.\n",
    "\n",
    "    Args:\n",
    "        left_data (DataFrame): Sensor data from left foot.\n",
    "        right_data (DataFrame): Sensor data from right foot.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - Processed feature array of shape (T, total_features)\n",
    "            - Dictionary of normalizers and standardizers used per component\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract sensor data from the left foot\n",
    "    left_pressure = left_data.iloc[:, :35]      # Pressure sensor values\n",
    "    left_rotation = left_data.iloc[:, 35:38]    # Rotation (e.g., gyroscope)\n",
    "    left_accel = left_data.iloc[:, 38:41]       # Acceleration\n",
    "\n",
    "    # Extract sensor data from the right foot\n",
    "    right_pressure = right_data.iloc[:, :35]\n",
    "    right_rotation = right_data.iloc[:, 35:38]\n",
    "    right_accel = right_data.iloc[:, 38:41]\n",
    "\n",
    "    # Concatenate corresponding data from both feet along feature axis\n",
    "    pressure_combined = pd.concat([left_pressure, right_pressure], axis=1)\n",
    "    rotation_combined = pd.concat([left_rotation, right_rotation], axis=1)\n",
    "    accel_combined = pd.concat([left_accel, right_accel], axis=1)\n",
    "\n",
    "    # Fill NaN values with zero\n",
    "    pressure_combined = pressure_combined.fillna(0.0)\n",
    "    rotation_combined = rotation_combined.fillna(0.0)\n",
    "    accel_combined = accel_combined.fillna(0.0)\n",
    "\n",
    "    # Diagnostics\n",
    "    print(\"Checking pressure data for NaN or Inf...\")\n",
    "    print(\"Pressure NaN count:\", pressure_combined.isna().sum().sum())\n",
    "    print(\"Pressure Inf count:\", np.isinf(pressure_combined).sum().sum())\n",
    "\n",
    "    # Apply rolling average filter (e.g., 3-frame smoothing)\n",
    "    window_size = 3\n",
    "    pressure_combined = pressure_combined.rolling(window=window_size, center=True).mean()\n",
    "    rotation_combined = rotation_combined.rolling(window=window_size, center=True).mean()\n",
    "    accel_combined = accel_combined.rolling(window=window_size, center=True).mean()\n",
    "\n",
    "    # Interpolate missing values from rolling\n",
    "    pressure_combined = pressure_combined.bfill().ffill()\n",
    "    rotation_combined = rotation_combined.bfill().ffill()\n",
    "    accel_combined = accel_combined.bfill().ffill()\n",
    "\n",
    "    # Define scalers for normalization and standardization\n",
    "    pressure_normalizer = MinMaxScaler()\n",
    "    rotation_normalizer = MinMaxScaler()\n",
    "    accel_normalizer = MinMaxScaler()\n",
    "\n",
    "    pressure_standardizer = StandardScaler()\n",
    "    rotation_standardizer = StandardScaler()\n",
    "    accel_standardizer = StandardScaler()\n",
    "\n",
    "    # Apply normalization and then standardization\n",
    "    pressure_processed = pressure_standardizer.fit_transform(\n",
    "        pressure_normalizer.fit_transform(pressure_combined)\n",
    "    )\n",
    "    rotation_processed = rotation_standardizer.fit_transform(\n",
    "        rotation_normalizer.fit_transform(rotation_combined)\n",
    "    )\n",
    "    accel_processed = accel_standardizer.fit_transform(\n",
    "        accel_normalizer.fit_transform(accel_combined)\n",
    "    )\n",
    "\n",
    "    # Concatenate all processed features\n",
    "    input_features = np.concatenate([\n",
    "        pressure_processed,\n",
    "        rotation_processed,\n",
    "        accel_processed,\n",
    "    ], axis=1)\n",
    "\n",
    "    # Return processed data and transformation metadata\n",
    "    return {\n",
    "    'pressure': {\n",
    "        'min': pressure_normalizer.data_min_.tolist(),\n",
    "        'max': pressure_normalizer.data_max_.tolist(),\n",
    "        'mean': pressure_standardizer.mean_.tolist(),\n",
    "        'std': pressure_standardizer.scale_.tolist()\n",
    "    },\n",
    "    'rotation': {\n",
    "        'min': rotation_normalizer.data_min_.tolist(),\n",
    "        'max': rotation_normalizer.data_max_.tolist(),\n",
    "        'mean': rotation_standardizer.mean_.tolist(),\n",
    "        'std': rotation_standardizer.scale_.tolist()\n",
    "    },\n",
    "    'accel': {\n",
    "        'min': accel_normalizer.data_min_.tolist(),\n",
    "        'max': accel_normalizer.data_max_.tolist(),\n",
    "        'mean': accel_standardizer.mean_.tolist(),\n",
    "        'std': accel_standardizer.scale_.tolist()\n",
    "    }}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d7a368a-563a-4048-94d5-0c6250df3e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pressure_all shape: (669238, 70)\n",
      "rotation_all shape: (669238, 6)\n",
      "accel_all shape: (669238, 6)\n",
      "已保存到 preprocess_metadata.json\n",
      "{'pressure': {'min': [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'max': [28.31088817, 29.00969344, 19.29574592, 4.965358054418779, 11.29641882, 8.690876979, 4.881950908, 5.371460629, 5.749220649, 15.69268082, 17.33835422, 12.44301679, 9.600404006, 15.26126627, 12.56730858, 4.302325568, 8.661231666, 9.175532174, 12.13741439, 29.09281089, 12.47940122, 12.58108964, 20.23554779, 31.06069379, 15.68360915, 12.00303024, 16.35584409, 50.0, 21.91780997, 13.29657974, 12.05457711, 38.09655204, 50.0, 21.745501726961983, 50.0, 7.114677869262327, 6.863688990993712, 50.0, 16.524792157484217, 8.252895099211338, 50.0, 50.0, 16.14755591854227, 13.848197405555126, 11.884362731501431, 10.094363378559056, 50.0, 25.00032613253253, 50.0, 16.378677857750628, 7.368267023338652, 7.855783453746736, 9.996836887384973, 17.673932367673352, 50.0, 6.304687002708363, 8.954699068684583, 17.069000650963194, 14.971938914700818, 16.954511954556498, 20.43139019988426, 38.15270720724924, 21.93387526460388, 22.712075423749543, 17.14034422559111, 25.459234016683627, 17.921728106852143, 21.88243712217368, 50.0, 29.38840554183939], 'mean': [1.3989762334521518, 0.6687256045153899, 0.1357800575863095, 0.19288799606745982, 0.6383382601226179, 0.699620797625743, 0.4129118828679303, 0.1879788376128777, 0.28938007687402323, 1.1842203160756415, 2.1544574861171015, 1.7657515572202969, 1.764911339276431, 4.1767148876879645, 3.8880570274257864, 0.35473744229844795, 1.3680321808447224, 0.9726632392502568, 1.8724010904333723, 1.5477456654152686, 2.386698160108204, 3.1456023526809735, 1.177325842963726, 2.9350349719356994, 2.7289303386801076, 1.8577591887364837, 3.5648575447955726, 14.612734986301293, 2.997571879740851, 5.871460623794551, 3.0473137785922924, 6.867563623810271, 7.207801364745213, 6.182385668271473, 15.450921219560643, 0.09243483785947805, 0.4536605823264892, 0.05821393743078708, 0.3554778933384854, 1.970091956243421, 0.10891568735160359, 1.5057276866291665, 1.7597960182002466, 2.467259337554055, 2.89625973748458, 0.6708195849408982, 1.9659615976393658, 4.543463509668889, 1.961366173433691, 3.2975384822028384, 1.1370771373023518, 1.8274910311707013, 1.7031262314613635, 3.12878584262514, 1.2307885632479818, 1.36381154173999, 1.7071780031200254, 5.100359857946873, 5.35360774086969, 5.924402791841762, 3.835419356703981, 6.196646973218769, 6.931062539396037, 5.792993580913543, 5.197940139109195, 4.4412039811406565, 4.301814743261702, 6.47700335048642, 11.160684260456058, 4.790404052245105], 'std': [1.8666676772935926, 1.057108101331824, 0.49269605067219724, 0.37018622375223603, 0.8080744688815895, 0.8519486293498219, 0.5855770945004016, 0.36604399894132517, 0.41403108933960786, 1.4414561734974065, 2.0407095398561275, 1.5938958212003562, 1.450596411393859, 2.621439711888323, 2.2721961476560564, 0.4421893447568005, 1.5606821328065315, 1.2573264684313583, 2.0985363899706444, 2.0702737906124473, 2.6626881691879616, 2.712385151732768, 1.2729815871267276, 3.5369347550737347, 2.5539368567235825, 1.5442251064818517, 3.4631707946778016, 21.69074472215247, 3.426105102221084, 3.334135207096902, 2.6204439096735137, 5.58519199079405, 7.385523424200672, 5.334650882575701, 16.445978794718147, 0.2146650792051494, 0.7810773958140498, 0.44024547212957793, 0.6799776778822368, 1.6998774089918642, 0.4814967975130141, 1.667063534981961, 1.775361561909356, 2.1801117540049804, 1.5927174779380364, 0.8527190730800309, 3.401669597268149, 2.9668444891631007, 1.9108628609786324, 2.319555267774297, 1.3194121939526382, 1.8847458632079421, 1.7292254800971247, 2.65915716332068, 2.5038461524012563, 1.4972405614527413, 1.7517925270141392, 3.6298867576790137, 3.6621608961929146, 3.4429503277044446, 3.212271832293431, 4.379742584187837, 4.385174824310472, 3.739544613045766, 3.6559897808916264, 4.32355772010315, 3.2638325369814414, 5.0252018812908235, 14.121460369202156, 4.980032358550546]}, 'rotation': {'min': [-566.1621094, -509.0331726, -319.7631836, -525.20751953125, -275.57373046875, -468.6889343261719], 'max': [783.0199584960938, 254.9438324, 356.2011414, 636.71875, 278.564453125, 419.2504577636719], 'mean': [1.664846550480904, 1.1110957566911859, 0.37486724764766227, 1.3746400951142081, 0.47390912193627965, -0.5233960215919646], 'std': array([36.57976117, 32.0492821 , 39.85836736, 36.5282814 , 26.53133109,\n",
      "       41.27019793])}, 'accel': {'min': [-3.8648681640625, -4.0, -3.728393555, -3.816650390625, -4.0, -3.6121826171875], 'max': [1.771606445, 3.99987793, 3.047729492, 1.4481201171875, 3.9998779296875, 3.17724609375], 'mean': [-0.9343056847422876, -0.1500225373408685, 0.0739031429340849, -0.9544335365469262, 0.02805315284081135, 0.1603686892582555], 'std': array([0.21630966, 0.28078329, 0.26359605, 0.19337196, 0.30178453,\n",
      "       0.1969244 ])}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "summary=compute_data_statistics_combined(dataset)\n",
    "with open('preprocess_metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=4, default=lambda o: o.tolist() if isinstance(o, np.ndarray) else o)\n",
    "print(\"已保存到 preprocess_metadata.json\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0b55a32-1294-4b56-9928-fe913d0ba81b",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 169\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction process completed successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 146\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    143\u001b[0m pressure_data_left \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/20241115test3/insoleSensor/20241115_155500_left.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    144\u001b[0m pressure_data_right \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/20241115test3/insoleSensor/20241115_155500_right.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, skiprows\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    147\u001b[0m     summary \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    149\u001b[0m summary \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    150\u001b[0m sensor: {k: np\u001b[38;5;241m.\u001b[39marray(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m stat\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sensor, stat \u001b[38;5;129;01min\u001b[39;00m summary\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    152\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.json'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def preprocess_pressure_data(left_data, right_data, value):\n",
    "    \"\"\"圧力、回転、加速度データの前処理\"\"\"\n",
    "    # 左足データから各種センサー値を抽出\n",
    "    left_pressure = left_data.iloc[:35]\n",
    "    left_rotation = left_data.iloc[35:38]\n",
    "    left_accel = left_data.iloc[38:41]\n",
    "    # 右足データから各種センサー値を抽出\n",
    "    right_pressure = right_data.iloc[:35]\n",
    "    right_rotation = right_data.iloc[35:38]\n",
    "    right_accel = right_data.iloc[38:41]\n",
    "\n",
    "    # データの結合\n",
    "    pressure_combined = pd.concat([left_pressure, right_pressure], axis=0)\n",
    "    rotation_combined = pd.concat([left_rotation, right_rotation], axis=0)\n",
    "    accel_combined = pd.concat([left_accel, right_accel], axis=0)\n",
    "\n",
    "    pressure_combined = pressure_combined.ffill().bfill()\n",
    "    rotation_combined = rotation_combined.ffill().bfill()\n",
    "    accel_combined = accel_combined.ffill().bfill()\n",
    "\n",
    "    # 正規化と標準化\n",
    "    def normalize_and_standardize(data, stats):\n",
    "        # Min-Max normalization\n",
    "        normed = (data - stats['min']) / (stats['max'] - stats['min'] + 1e-8)\n",
    "        # Standardization\n",
    "        standardized = (normed - stats['mean']) / (stats['std'] + 1e-8)\n",
    "        return standardized\n",
    "\n",
    "    pressure_processed = normalize_and_standardize(pressure_combined, value['pressure'])\n",
    "    rotation_processed = normalize_and_standardize(rotation_combined, value['rotation'])\n",
    "    accel_processed = normalize_and_standardize(accel_combined, value['accel'])\n",
    "\n",
    "    # すべての特徴量を結合（246次元になるはず）\n",
    "    input_features = np.concatenate([\n",
    "        pressure_processed,\n",
    "        rotation_processed,\n",
    "        accel_processed,\n",
    "    ], axis=0)\n",
    "\n",
    "    return input_features\n",
    "def predict_skeleton(input,summary):\n",
    "    # データの読み込みと前処理\n",
    "    pres_left=input['left']\n",
    "    pres_right=input['right']\n",
    "    \n",
    "    input_features = preprocess_pressure_data(pres_left, pres_right, summary)\n",
    "    input_features = input_features.reshape(1, input_features.shape[0])\n",
    "    \n",
    "    # 入力の次元数を取得\n",
    "    seq_length = 3\n",
    "    window_size = 1\n",
    "    m=1\n",
    "    input_dim = input_features.shape[1]\n",
    "    num_joints = 21\n",
    "\n",
    "    # デバイスの設定\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # モデルの初期化（固定パラメータを使用）\n",
    "    model = EnhancedSkeletonTransformer(\n",
    "        input_dim=input_dim,\n",
    "        d_model=512,\n",
    "        nhead=8,\n",
    "        num_encoder_layers=6,\n",
    "        num_joints=num_joints,\n",
    "        num_dims=3,\n",
    "        dropout=0.1,\n",
    "        seq_length=seq_length,\n",
    "        window_size=window_size\n",
    "    ).to(device)\n",
    "\n",
    "    # チェックポイントの読み込み（weights_only=Trueを追加）\n",
    "    checkpoint = torch.load('./weight/best_skeleton_model_3_1.pth', map_location=device, weights_only=True)\n",
    "    \n",
    "    # モデルの重みを読み込み\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    print(\"Model loaded successfully\")\n",
    "\n",
    "    action=torch.zeros((10,window_size,63)).to(device)\n",
    "    num=np.zeros(10)\n",
    "    print(action.shape)\n",
    "    # 予測の実行\n",
    "    print(\"Making predictions...\")\n",
    "    start_time = time.time()\n",
    "    predictions=torch.zeros(1,63).to(device)\n",
    "    with torch.no_grad():\n",
    "        skeleton_last=torch.zeros((seq_length,63))\n",
    "        skeleton_last=skeleton_last.unsqueeze(0).to(device)\n",
    "        for i in range(1):\n",
    "            input_tensor = torch.FloatTensor(input_features)[i].to(device)\n",
    "            input_tensor = input_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "            if i%20==0:\n",
    "                skeleton_last=torch.zeros_like(skeleton_last)\n",
    "            skeleton_predict_seq=model(input_tensor,skeleton_last)\n",
    "            skeleton_predict_seq=skeleton_predict_seq.squeeze(0)\n",
    "            skeleton_predict=torch.zeros(63).to(device)\n",
    "            for j in range(window_size):\n",
    "                action[i+j,int(num[i+j])]=skeleton_predict_seq[j,:]\n",
    "                num[i+j]+=1\n",
    "                #print(f\"j={j},i+j={i+j},num[i+j}]={int(num[i+j])}\")\n",
    "            weights = compute_exponential_weights(int(num[i]), m).to(device)\n",
    "            for j in range(int(num[i])):\n",
    "                skeleton_predict+=weights[j]*action[i,int(num[i])-1-j]\n",
    "            predictions[i]=skeleton_predict\n",
    "            for j in range(seq_length-1):\n",
    "                skeleton_last[0,j]=skeleton_last[0,j+1]\n",
    "            skeleton_last[0,seq_length-1]=skeleton_predict\n",
    "    '''\n",
    "    # 予測の実行\n",
    "    print(\"Making predictions...\")\n",
    "    predictions=torch.zeros(min_length,63).to(device)\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.FloatTensor(input_features).to(device)\n",
    "        input_tensor=input_tensor.to(device)\n",
    "        print(input_tensor.shape,skeleton_data.shape)\n",
    "        predictions=model(input_tensor,skeleton_data)\n",
    "    '''\n",
    "    print(f\"Prediction shape: {predictions.shape}\")\n",
    "\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Prediction took {elapsed_time} seconds\")\n",
    "    return predictions\n",
    "\n",
    "def save_predictions(predictions, output_file='./output/predicted_skeleton.csv'):\n",
    "    # 予測結果をデータフレームに変換\n",
    "    num_joints = predictions.shape[1] // 3\n",
    "    columns = []\n",
    "    for i in range(num_joints):\n",
    "        columns.extend([f'X.{i*2+1}', f'Y.{i*2+1}', f'Z.{i*2+1}'])\n",
    "    \n",
    "    df_predictions = pd.DataFrame(predictions, columns=columns)\n",
    "    df_predictions.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions saved to {output_file}\")\n",
    "\n",
    "def main():\n",
    "    skeleton_data = pd.read_csv('./data/20241115test3/Opti-track/Take 2024-11-15 03.50.00 PM.csv')\n",
    "    pressure_data_left = pd.read_csv('./data/20241115test3/insoleSensor/20241115_155500_left.csv', skiprows=1)\n",
    "    pressure_data_right = pd.read_csv('./data/20241115test3/insoleSensor/20241115_155500_right.csv', skiprows=1)\n",
    "    \n",
    "    with open('data.json', 'r') as f:\n",
    "        summary = json.load(f)\n",
    "\n",
    "    summary = {\n",
    "    sensor: {k: np.array(v) for k, v in stat.items()}\n",
    "    for sensor, stat in summary.items()\n",
    "    }\n",
    "    print(summary)\n",
    "\n",
    "    input = {}\n",
    "    input['left']=pressure_data_left.iloc[0,:]\n",
    "    input['right']=pressure_data_right.iloc[0,:]\n",
    "\n",
    "    print(\"Starting prediction process...\")\n",
    "    predictions = predict_skeleton(input,summary)\n",
    "    \n",
    "    print(\"\\nSaving predictions...\")\n",
    "    save_predictions(predictions)\n",
    "    print(predictions)\n",
    "    \n",
    "    print(\"Prediction process completed successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0fe532-1378-491a-81dc-3f896e629894",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12d0539-99f8-46ec-be84-01a8cea62a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da066fb3-f24e-4fd1-89c9-22f7165cb579",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
